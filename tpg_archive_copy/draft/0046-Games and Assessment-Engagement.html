<!DOCTYPE html>
<html><head>
<title>0046: Games and Assessment/Engagement</title>
</head>
<body>
<h2>Games and Assessment/Engagement</h2>
<h4>2009-05-29 01:33:12</h4>
<h4>status: draft</h4>
<h4>author: Bryan</h4>
<p>James <br/>
if impacting learning - set of choices: <br/>
a: teach facts or teach problem solving?  problem solving is superior - uses facts as tools - therefore value added.  facts are only facts<br/>
b: teach skills or change as a person?  changing a person to identify with a domain predicts the acquisition of skills, but teaching skills does not predict change as a person.<br/>
c: change by giving a lot of knowledge or look at the choices made in a domain - looking at the choices they make within a domain predicts the knowledge they have.  looking at knowledge does not predict the choices that they will make. (e.g. in the sims - looking at the product of design in the sims <br/>
d: look at a trajectory of learning (over time) or look at a one-shot assessment?  - static assessment doesn't predict the trajectory.  but trajectory predicts <br/>
development (growth curve) is U-shaped.<br/>
e: learn in communities or learn alone?  learning in communities - results predict results of solo learning as well.<br/>
<br/>
Katie Selen - game designer background - design perspective - ask the question when we make decisions to design games - whether for purposes of civic engagement or otherwise - must make design choices that allow you to assess<br/>
assessment in games comes around after games are made, for the most part.<br/>
it should come at the beginning. <br/>
have to distribute your assessment and learning goals across the ECOLOGY of the game?  rather than the game trying to do everything.  <br/>
what are the pieces that are data driven, how to track, how to structure the data for accessibility for researchers.<br/>
<br/>
Constance -<br/>
cognition and learning research around play/entertainment spaces<br/>
what do audiences value in their playspaces, translate that to other audiences, draw parallels, identify alignments.<br/>
what is the unit(s) of analysis?  critical assessment question<br/>
assessment that is useful for future action and useful for the community.<br/>
<br/>
kurt<br/>
high-stakes vs. low-stakes assessment.<br/>
actions where a system can't categorize?<br/>
gamers are pretty good at knowing when they want high or low stakes assessment<br/>
systems used to sort people are the wrong sorts of tools <br/>
<br/>
katie<br/>
one thing games do really well -> games makes performance stats available to players - lots of data - players eat it up.  <br/>
highly relevant to assessment in general - how do you make data a useful and friendly tool in an academic environment, for example?  rather than say - turn in paper, oh i got an F, and thats the end of it.<br/>
one direction - kids building smart-tools that are embedded moments of assessment - build inventories of tools to think with<br/>
how to embed assessments into the actual learning activity to become tools for the players?<br/>
look into which </p>
<h4>Comments:</h4>

</body>
</html>